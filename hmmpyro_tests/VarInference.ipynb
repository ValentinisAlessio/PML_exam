{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation of Transition matrix and Emission parameters for each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pyro\n",
    "from pyro import poutine\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, TraceEnum_ELBO\n",
    "from pyro.infer.autoguide import AutoDelta\n",
    "from pyro.optim import Adam\n",
    "import pandas as pd\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/hulls_df_compact_matchday1.csv\")\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA:** provare a scalare i dati per vedere:\n",
    "1. se il modello fitta più veloce\n",
    "2. se i parametri finali sono più sensati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = torch.tensor(data[\"AwayHull\"].values)\n",
    "hidden_dim = 2\n",
    "sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(sequence, hidden_dim, include_prior=True):\n",
    "    length = len(sequence)\n",
    "    with poutine.mask(mask=include_prior):\n",
    "        # Transition probabilities\n",
    "        probs_x = pyro.sample(\n",
    "            \"probs_x\",\n",
    "            dist.Dirichlet(0.9 * torch.eye(hidden_dim) + 0.1).to_event(),\n",
    "        )\n",
    "        # Emission probabilities (1-dimensional for the area)\n",
    "        probs_alpha = pyro.sample(\n",
    "            \"probs_alpha\",\n",
    "            dist.Gamma(1.0, 1.0).expand([hidden_dim]).to_event(1)\n",
    "        )\n",
    "\n",
    "        probs_beta = pyro.sample(\n",
    "            \"probs_beta\",\n",
    "            dist.Gamma(1.0, 1.0).expand([hidden_dim]).to_event(1)\n",
    "        )\n",
    "    \n",
    "    x = 0  # Initial hidden state\n",
    "    for t in pyro.markov(range(length)):\n",
    "        x = pyro.sample(\n",
    "            f\"x_{t}\",\n",
    "            dist.Categorical(probs_x[x]),\n",
    "            infer={\"enumerate\": \"parallel\"},\n",
    "        )\n",
    "        pyro.sample(\n",
    "            f\"y_{t}\",\n",
    "            dist.Gamma(probs_alpha[x], probs_beta[x]),\n",
    "            obs=sequence[t],\n",
    "        )\n",
    "# Define the guide (variational distribution)\n",
    "guide = AutoDelta(poutine.block(model, expose=[\"probs_x\", \"probs_alpha\", \"probs_beta\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**⚠️ DANGER ZONE ⚠️**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = Adam({\"lr\": 0.01})\n",
    "\n",
    "# Inference algorithm\n",
    "elbo = TraceEnum_ELBO(max_plate_nesting=1)\n",
    "svi = SVI(model, guide, optimizer, loss=elbo)\n",
    "\n",
    "# Training\n",
    "num_steps = 1000\n",
    "tqdm_bar = tqdm.tqdm(range(num_steps))\n",
    "for step in tqdm_bar:\n",
    "    loss = svi.step(sequence, hidden_dim)\n",
    "    if step % 100 == 0:\n",
    "         tqdm_bar.set_postfix({'LOSS': loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = guide(sequence,hidden_dim)\n",
    "# can i save posterior?\n",
    "posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(posterior,\"parameters/singleHMM_away.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_state1=6.5119/0.0058\n",
    "print(f\">> Mean of the Convex Hull for home team (STATE 1): {mean_state1:.2f} m^2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_state2=35.4986/0.0493\n",
    "print(f\">> Mean of the Convex Hull for home team (STATE 2): {mean_state2:.2f} m^2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copula model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time [s]</th>\n",
       "      <th>Period</th>\n",
       "      <th>HomeHull</th>\n",
       "      <th>AwayHull</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>597.464015</td>\n",
       "      <td>810.521383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>647.023869</td>\n",
       "      <td>944.579702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>668.716043</td>\n",
       "      <td>1061.570185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>657.826932</td>\n",
       "      <td>1236.516611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>684.343047</td>\n",
       "      <td>1470.159649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time [s]  Period    HomeHull     AwayHull\n",
       "0       2.0     1.0  597.464015   810.521383\n",
       "1       4.0     1.0  647.023869   944.579702\n",
       "2       6.0     1.0  668.716043  1061.570185\n",
       "3       8.0     1.0  657.826932  1236.516611\n",
       "4      10.0     1.0  684.343047  1470.159649"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/hulls_every2_matchday2.csv\")\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1970, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy_sequence = torch.tensor(data[[\"HomeHull\",\"AwayHull\"]].values/100) #we divide by 100 to avoid computational issues (insted of m^2 we use dm^2)\n",
    "xy_sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_gamma_cdf(x, shape, rate):\n",
    "    # Generate 1000 random samples from the gamma distribution\n",
    "    # Think about setting a seed to avoid too much stochasticity\n",
    "    #torch.manual_seed(3407)\n",
    "    samples = torch.distributions.Gamma(shape, rate).sample((3500,))\n",
    "    return (samples <= x).float().mean()\n",
    "\n",
    "def copula_term_log(theta: torch.tensor, u: torch.tensor, v: torch.tensor):\n",
    "    log_numerator = torch.log(theta) + torch.log(torch.exp(theta) - 1.0) + theta * (1.0 + u + v)\n",
    "    denominator = (torch.exp(theta) - torch.exp(theta + theta * u) + torch.exp(theta * (u + v)) - torch.exp(theta + theta * v))**2\n",
    "    log_denominator = torch.log(denominator)\n",
    "    return log_numerator - log_denominator\n",
    "\n",
    "def copulamodel_log_pdf(x,y,shape1,rate1,shape2,rate2,theta):\n",
    "    g1_lpdf= dist.Gamma(shape1,rate1).log_prob(x)\n",
    "    g2_lpdf= dist.Gamma(shape2,rate2).log_prob(y)\n",
    "    u= empirical_gamma_cdf(x, shape1, rate1)\n",
    "    v= empirical_gamma_cdf(y, shape2, rate2)\n",
    "    # Qui pensare se fare una if su u e v diversi da circa 0...in quel caso non calcolare il copula term (lo lascio nullo)\n",
    "    lpdf=g1_lpdf+g2_lpdf\n",
    "    if (torch.abs(u) > 1e-6) & (torch.abs(v) > 1e-6):\n",
    "        lpdf += copula_term_log(theta=theta,u=u,v=v)\n",
    "    return lpdf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu=np.array([6.51,12.34,8.51,10.96,10.31,8.53,12.77,7.29])\n",
    "s=np.array([1.3,2.11,2.83,3.41,1.74,1.54,3.2,2.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=mu**2/s**2\n",
    "beta= mu/s**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25.07698225 34.20309517  9.04245277 10.33028612 35.10903025 30.68008939\n",
      " 15.92508789  8.503056  ]\n",
      "[3.85207101 2.7717257  1.06256789 0.94254435 3.40533756 3.59672795\n",
      " 1.24707031 1.1664    ]\n"
     ]
    }
   ],
   "source": [
    "print(alpha)\n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.108759980297002\n",
      "2.2555555970448706\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(alpha))\n",
    "print(np.mean(beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(sequence, hidden_dim, include_prior=True):\n",
    "    n_obs = sequence.shape[0]\n",
    "    with poutine.mask(mask=include_prior):\n",
    "        #---------------------------------------------------------------------\n",
    "        # Transition probabilities\n",
    "        probs_x = pyro.sample(\n",
    "            \"probs_x\",\n",
    "            dist.Dirichlet(0.9 * torch.eye(hidden_dim) + 0.1).to_event(),\n",
    "        )\n",
    "        #---------------------------------------------------------------------\n",
    "        # Prior for the parameters of emission probabilities \n",
    "        probs_alpha1 = pyro.sample(\n",
    "            \"probs_alpha1\",\n",
    "            dist.Gamma(concentration=15.0,rate=0.8).expand([hidden_dim]).to_event(1)\n",
    "        )\n",
    "\n",
    "        probs_beta1 = pyro.sample(\n",
    "            \"probs_beta1\",\n",
    "            dist.Gamma(concentration=1.0,rate=1.0).expand([hidden_dim]).to_event(1)\n",
    "        )\n",
    "        probs_alpha2 = pyro.sample(\n",
    "            \"probs_alpha2\",\n",
    "            dist.Gamma(concentration=15.0,rate=0.8).expand([hidden_dim]).to_event(1)\n",
    "        )\n",
    "\n",
    "        probs_beta2 = pyro.sample(\n",
    "            \"probs_beta2\",\n",
    "            dist.Gamma(concentration=1.0,rate=1.0).expand([hidden_dim]).to_event(1)\n",
    "        )\n",
    "        #---------------------------------------------------------------------\n",
    "        # Prior for theta\n",
    "        theta = pyro.sample(\n",
    "            \"theta\",\n",
    "            dist.Gamma(5.0,0.7).expand([hidden_dim]).to_event(1)\n",
    "        )\n",
    "        \n",
    "    \n",
    "    x = 0  # Initial hidden state\n",
    "    for t in pyro.markov(range(n_obs)):\n",
    "        x = pyro.sample(\n",
    "            f\"x_{t}\",\n",
    "            dist.Categorical(probs_x[x]),\n",
    "            infer={\"enumerate\": \"parallel\"},\n",
    "        )\n",
    "        log_pdf = copulamodel_log_pdf(\n",
    "            x=sequence[t,0],\n",
    "            y=sequence[t,1],\n",
    "            shape1=probs_alpha1[x],\n",
    "            rate1=probs_beta1[x],\n",
    "            shape2=probs_alpha2[x],\n",
    "            rate2=probs_beta2[x],\n",
    "            theta=theta[x]\n",
    "        )\n",
    "        pyro.factor(f\"xy_{t}\", log_pdf)\n",
    "        \n",
    "\n",
    "guide = AutoDelta(poutine.block(model, expose=[\"probs_x\",\n",
    "                                               \"probs_alpha1\",\n",
    "                                               \"probs_beta1\",\n",
    "                                               \"probs_alpha2\",\n",
    "                                               \"probs_beta2\",\n",
    "                                               \"theta\"\n",
    "                                               ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [25:36<00:00,  3.07s/it, LOSS=8.84e+3]\n"
     ]
    }
   ],
   "source": [
    "# Optimizer\n",
    "optimizer = Adam({\"lr\": 0.01})\n",
    "\n",
    "# Inference algorithm\n",
    "elbo = TraceEnum_ELBO(max_plate_nesting=1)\n",
    "svi = SVI(model, guide, optimizer, loss=elbo)\n",
    "\n",
    "# Training\n",
    "hidden_dim=4\n",
    "num_steps = 500\n",
    "tqdm_bar = tqdm.tqdm(range(num_steps))\n",
    "for step in tqdm_bar:\n",
    "    loss = svi.step(xy_sequence, hidden_dim)\n",
    "    #if step % 50 == 0:\n",
    "    tqdm_bar.set_postfix({'LOSS': loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'probs_x': tensor([[0.8516, 0.0358, 0.0887, 0.0239],\n",
       "         [0.0233, 0.9129, 0.0251, 0.0387],\n",
       "         [0.0158, 0.0269, 0.9339, 0.0234],\n",
       "         [0.0120, 0.0526, 0.0476, 0.8878]], grad_fn=<ExpandBackward0>),\n",
       " 'probs_alpha1': tensor([ 5.7242, 10.2903, 17.4644, 14.0914], grad_fn=<ExpandBackward0>),\n",
       " 'probs_beta1': tensor([0.9758, 1.6586, 1.6569, 1.3222], grad_fn=<ExpandBackward0>),\n",
       " 'probs_alpha2': tensor([ 6.2696, 13.1638, 16.5609, 13.3948], grad_fn=<ExpandBackward0>),\n",
       " 'probs_beta2': tensor([1.3575, 1.1748, 2.3969, 1.0639], grad_fn=<ExpandBackward0>),\n",
       " 'theta': tensor([2.7437, 0.9762, 0.8987, 4.6567], grad_fn=<ExpandBackward0>)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior = guide(xy_sequence,hidden_dim)\n",
    "posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Mean of the Convex Hull for home team (STATE 1): 586.64 m^2\n",
      ">> Mean of the Convex Hull for away team (STATE 1): 461.86 m^2\n",
      ">> Mean of the Convex Hull for home team (STATE 2): 620.40 m^2\n",
      ">> Mean of the Convex Hull for away team (STATE 2): 1120.55 m^2\n",
      ">> Mean of the Convex Hull for home team (STATE 3): 1054.04 m^2\n",
      ">> Mean of the Convex Hull for away team (STATE 3): 690.94 m^2\n",
      ">> Mean of the Convex Hull for home team (STATE 4): 1065.78 m^2\n",
      ">> Mean of the Convex Hull for away team (STATE 4): 1259.06 m^2\n"
     ]
    }
   ],
   "source": [
    "meanH_state1 = posterior[\"probs_alpha1\"][0]/posterior[\"probs_beta1\"][0]*100\n",
    "meanA_state1 = posterior[\"probs_alpha2\"][0]/posterior[\"probs_beta2\"][0]*100\n",
    "meanH_state2 = posterior[\"probs_alpha1\"][1]/posterior[\"probs_beta1\"][1]*100\n",
    "meanA_state2 = posterior[\"probs_alpha2\"][1]/posterior[\"probs_beta2\"][1]*100\n",
    "meanH_state3 = posterior[\"probs_alpha1\"][2]/posterior[\"probs_beta1\"][2]*100\n",
    "meanA_state3 = posterior[\"probs_alpha2\"][2]/posterior[\"probs_beta2\"][2]*100\n",
    "meanH_state4 = posterior[\"probs_alpha1\"][3]/posterior[\"probs_beta1\"][3]*100\n",
    "meanA_state4 = posterior[\"probs_alpha2\"][3]/posterior[\"probs_beta2\"][3]*100\n",
    "\n",
    "print(f\">> Mean of the Convex Hull for home team (STATE 1): {meanH_state1:.2f} m^2\")\n",
    "print(f\">> Mean of the Convex Hull for away team (STATE 1): {meanA_state1:.2f} m^2\")\n",
    "print(f\">> Mean of the Convex Hull for home team (STATE 2): {meanH_state2:.2f} m^2\")\n",
    "print(f\">> Mean of the Convex Hull for away team (STATE 2): {meanA_state2:.2f} m^2\")\n",
    "print(f\">> Mean of the Convex Hull for home team (STATE 3): {meanH_state3:.2f} m^2\")\n",
    "print(f\">> Mean of the Convex Hull for away team (STATE 3): {meanA_state3:.2f} m^2\")\n",
    "print(f\">> Mean of the Convex Hull for home team (STATE 4): {meanH_state4:.2f} m^2\")\n",
    "print(f\">> Mean of the Convex Hull for away team (STATE 4): {meanA_state4:.2f} m^2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(posterior,\"parameters/doubleHMM_4states_matchday2_every2sec.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qui mi dava un **NotImplementedError: the derivative for 'igamma: input' is not implemented**\n",
    "\n",
    "ChatGPT dice *\"The error NotImplementedError: the derivative for 'igamma: input' is not implemented suggests that there is an issue with calculating the gradient for some operations involving the incomplete gamma function, which might be used internally by PyTorch when working with Gamma distributions. To work around this, we can implement the gradient ourselves using a workaround. One approach is to approximate the CDF of the Gamma distribution with a method that supports autograd. Alternatively, using numerical integration or approximation methods can avoid using the incomplete gamma function\"*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
